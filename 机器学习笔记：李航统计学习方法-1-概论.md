## 1、机器学习与数学建模

统计学习是从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到数据的分析与预测中。统计学习和数学建模都是要建立数学模型来解决问题，那么两者有什么不同呢？

### 1.1、统计机器学习方法的步骤

> （1）得到一个有限的训练数据集合； \
（2）确定包含所有可能的模型的**假设空间**，即模型的集合； \
（3）确定模型选择的准则，即学习的策略； \
（4）实现求解最优模型的算法，即学习的算法； \
（5）通过学习算法选择最优模型； \
（6）利用最优模型对新数据进行预测或分析；

### 1.2、数学建模的步骤

> （1）提出问题； \
（2）选择建模方法； \
（3）推导模型的数学表达式； \
（4）求解模型； \
（5）回答问题； \
*参考《数学建模方法与分析》，Mark M. Meerschaent著，刘来福等译。*

数学建模需要根据各变量的关系来推导出**数学表达式**，然后根据这些表达式来求解出模型。统计学习方法中，变量（特征）规模较庞大，他们之间的关系也较复杂，一般很难直接推导出变量之间的数学表达式（只知道模型的假设空间）；另外统计学习特别强调的是**数据**，从数据的统计规律性中自动总结出变量之间的关系，即得到模型。

## 2、机器学习三要素

### 2.1、模型：输入和输出之间的映射关系

假设空间是输入与输出的映射关系（模型）组成的空间。

非概率模型用决策函数表示：$Y=f(X)$。

分类问题中，非概率模型的输出值为类别标签，如感知机、SVM、决策树等属于非概率模型。

概率模型用联合分布或者条件分布表示：$P(X,Y)$或$P(Y|X)$。

分类问题中，概率模型的输出值为类别标签，如逻辑回归、朴素贝叶斯等属于概率模型。

### 2.2、策略：以何种标准从假设空间中找出最优模型

#### 2.2.1、损失函数

在假设空间中选取模型$f$，对于给定的输入$X$，有相应的输出$f(X)$，这个输出与真实值$Y$之间的误差程度，可以用损失函数或者代价函数来度量。

> 损失函数是对于**单个样本**而言。

常用损失函数：

- 0-1损失函数：

$$
L(Y,f(X)) = 
\begin{cases}
   1,Y {=}\llap{/\,} f(X) \\
   0,Y = f(X)
\end{cases}
$$

> 该损失函数对参数不可微，难以用梯度来学习。

- 平方损失函数：

$$
L(Y,f(X)) = (Y-f(X))^2
$$

> 对参数可微。

- 绝对值损失函数：

$$
L(Y,f(X)) = |Y-f(X)|
$$

> 对参数分段可微。

- 对数损失函数：

$$
L(Y,P(Y|X)) = -logP(Y|X)
$$

> 对参数可微。


#### 2.2.2、期望风险

损失函数只体现出模型对于单个样本预测结果的好坏，如果要知道模型对于样本空间整体预测结果的性能，则需要计算损失函数在输入输出空间上的期望（即平均损失）。

$$
R_{exp}(f) = E_p[L(Y,f(X))] = \int_{X,Y}L(y,f(x))P(x,y)dxdy
$$

其中$P(X,Y)$是输入输出的联合概率分布。

这时理论上模型$f(X)$关于联合分布$P(X,Y)$的**平均意义**下的损失，称为风险函数或者**期望风险**。

用期望风险最小化求得的模型是最优解。

在实际中，输入输出空间是未知的，联合分布$P(X,Y)$也是未知的，所以期望风险无法直接计算。

#### 2.2.3、经验风险

给定一个训练数据集

$$
T=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}
$$

模型$f(X)$关于训练数据集的平均损失称为经验风险或者经验损失

$$
R_{emp}(f)=\frac {1}{N} \sum_{i=1}^{N} L(y_i,f(x_i))
$$

根据**大数定律**，当样本容量$N$趋于无穷大时，经验风险$R_{emp}(f)$趋于期望风险$R_{exp(f)}$。所以可以用经验风险来评估期望风险。

经验风险最小化策略：

$$
\min \limits_f \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i))
$$

现实中训练样本数目有限，有时很小，所以用经验风险估计期望风险往往不理想。

> 当样本数量小时，无法涵盖样本空间的全部信息，此时经验风险最小化从样本中除了学习到一部分全局信息外，还会很认真得学习样本集的局部信息（学习算法会提高模型的复杂度来表征这些局部信息）。在模型预测时就容易把样本集特有的局部特征当作预测依据，容易出现**过拟合**现象，模型的泛化能力变差。

#### 2.2.4、结构风险

为了防止过拟合，提出了结构风险，

$$
R_{srm}(f) = \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i)) + \lambda J(f)
$$


> 它在经验风险上加入了表示模型复杂度的正则化项$J(f)$，模型越复杂，$J(f)$越大。目的对模型复杂度进行惩罚，使其复杂度不能过高，即抑制模型学习样本集的局部信息。

结构风险最小化策略：

$$
\min \limits_f \frac{1}{N} \sum_{i=1}^{N} L(y_i,f(x_i)) + \lambda J(f)
$$

### 2.3、算法：最优化算法


在统计学习中，特别是在深度学习中，策略和算法是“技术”，一般是比较固定的，深度学习软件库一般会提供关于策略和算法的成熟的解决方案，但是模型是“技巧”，它有更多发挥的空间，也是重点和难点。